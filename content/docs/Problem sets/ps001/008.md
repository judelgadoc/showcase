# Exercise 08
{{< hint info >}}
Implement a pixelator video application and perform a benchmark of the results (color avg vs spatial coherence). How would you assess the visual quality of the results?
{{< /hint >}}

## Introduction
A pixel is any of the small discrete elements that together constitute an image (as on a television or digital screen), the word *Pixelated* is used to describe digital images in which individual pixels are discernable, as when you look closely at a large photo and can see the tiny dots that make up the image. [^1] In this exercise, we mean by pixelator an application capable of taking a media and make it pixelated

## Previous work
In the e-book of our class, a Pixelator of images using the library p5.quadrille.js[^2] can be found[^3]. GitHub user *mfmyip* created an open source code of a video and image Pixelator using Spatial coherence[^4]

## Considerations

Even though p5.quadrille.js says it works with objects of type p5.Image or p5.Graphics, and a video should work, this is not the case, or at least the implementation proved harder than expected.
The Pixelator made by mfmyip worked without libraries, so it was used as an inspiration for this exercise. mfmyip made unnecessary functionalities such as an option to toggle round pixels and it worked with both images and videos, but just for spatial coherence.
The main idea that makes this work is an array of pixels of the format

```javascript
pixels = [R0, G0, B0, A0, R1, G1, B1, A1, ...]
```

Where Ri := Red component of pixel i, Gi := Green component of pixel i, Bi := Blue component of pixel i, Ai := Alpha component of pixel i. According to the RGBA color model [^5] and moving from left to right across each row, then down each column.

Assuming an mp4 video doesn't have relevant values for the Alpha component, we will ignore them.

This 1-dimensional array can be used to implement both algorithms using arithmetic.

Following the same design philosophy of mfmyip, the P5 canvas contains only the video, and to control it we use keystrokes.

The following table specifies the available options to control the video

| Option                                                        | Key        |
|---------------------------------------------------------------|------------|
| Play/Pause                                                    | *P* or *p* |
| Mute/Unmute                                                   | *M* or *m* |
| Decrease pixel size                                           | *,*        |
| Increase pixel size                                           | *.*        |
| Toggle between original, spatial coherence and color average  | *T* or *t* |
| Take snapshot                                                 | *space*    |


{{< hint warning >}}
Click on the video before executing an option if it doesn't work, to ensure you are in the same context as the video 
{{< /hint >}}

{{< hint warning >}}
If there's a bug of a black screen when loading the page, please pause and unpause until the video starts, if there's a bug of Inf frame rate, toggle the video or change pixel size.
{{< /hint >}}

## Solution

{{< p5-iframe sketch="/visualcomputing/sketches/ps001/ex08.js" ver="1.6.0" width="720" height="724" >}}

The standard method to benchmark noise is the signal-to-noise ratio (SNR), which measures the "noise" compared to the real signal. We could take the original source as a base and compare that to the noise generated by the pixels

A proposal for a benchmark of the pixelated video {{< katex >}}x{{< /katex >}} against the original video {{< katex >}}y{{< /katex >}} could be, for a single frame
 
{{< katex display >}}
BenchmarkFrame(x, y, f) = sum(|Y_y - Y_x|)
{{< /katex >}}

or 

{{< katex display >}}
BenchmarkFrame(x, y, f) = avg(|Y_y - Y_x|)
{{< /katex >}}

Where the matrix {{< katex >}}Y_i{{< /katex >}} represents the Luma of video {{< katex >}}i{{< /katex >}}, frame {{< katex >}}f{{< /katex >}} in the color space YCbCr. We do this because the luma represents the perception of the human eye better than the RGB space [^6].
Therefore, an objective benchmark is to get the absolute value of the difference between two lumas pixel by pixel, and then reduce this to one dimension by either summing every result or averaging, because every pixel counts but we want something similar to a measure of central tendency.

To get the benchmark of the whole video, calculate for all frames and get the median. Values closer to {{< katex >}}0{{< /katex >}} are better.

Another benchmark to be aware of is the performance of the video, doing an average takes more computational work than just selecting a particular pixel, therefore Spatial Coherence should be faster. In this video, the original frame rate is about **60 to 61 fps**, whereas the frame rate using spatial coherence with default pixel size is about **13 fps**, and the frame rate using average with the same characteristic is about **10 to 12 fps**.

## Code
{{< details "Source code" >}}
<pre data-src="/visualcomputing/sketches/ps001/ex08.js" class="line-numbers"></pre>
{{< /details >}}

## Conclusions
The performance from the original video to the different methods of pixelation is highly noticeable, between these methods, due to the bigger computational requirements of color averaging, this last one is slower than the spatial coherence in about 1 frame per second.

## Future work
Implement the benchmarking using YCbCr.

## References
[^1]: “Definition of PIXEL,” Mar. 27, 2023.  [Online]. Available: https://www.merriam-webster.com/dictionary/pixel. [Accessed: Mar. 29, 2023]
[^2]: nakednous, “p5quadrille.js.” GitHub, Feb. 05, 2023 [Online]. Available: https://github.com/objetos/p5.quadrille.js/
[^3]: “Spatial Coherence | Visual Computing.”  [Online]. Available: https://visualcomputing.github.io/docs/visual_illusions/spatial_coherence/. [Accessed: Mar. 29, 2023]
[^4]: mfmyip, “Pixelator.” GitHub, 2020 [Online]. Available: https://github.com/mfmyip/Pixelator 
[^5]: “Portable Network Graphics (PNG) Specification (Second Edition).”  [Online]. Available: https://www.w3.org/TR/2003/REC-PNG-20031110/index.html. [Accessed: Mar. 29, 2023]
[^6]: H. Noda, N. Takao and M. Niimi, "Colorization in YCbCr Space and its Application to Improve Quality of JPEG Color Images," 2007 IEEE International Conference on Image Processing, San Antonio, TX, USA, 2007, pp. IV - 385-IV - 388, doi: [10.1109/ICIP.2007.4380035](https://doi.org/10.1109/ICIP.2007.4380035).

