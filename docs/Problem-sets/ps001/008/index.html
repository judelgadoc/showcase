<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Exercise 08 # Implement a pixelator video application and perform a benchmark of the results (color avg vs spatial coherence). How would you assess the visual quality of the results? Introduction # A pixel is any of the small discrete elements that together constitute an image (as on a television or digital screen), the word Pixelated is used to describe digital images in which individual pixels are discernable, as when you look closely at a large photo and can see the tiny dots that make up the image."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Exercise 08 # Implement a pixelator video application and perform a benchmark of the results (color avg vs spatial coherence). How would you assess the visual quality of the results? Introduction # A pixel is any of the small discrete elements that together constitute an image (as on a television or digital screen), the word Pixelated is used to describe digital images in which individual pixels are discernable, as when you look closely at a large photo and can see the tiny dots that make up the image."><meta property="og:type" content="article"><meta property="og:url" content="https://judelgadoc.github.io/visualcomputing/docs/Problem-sets/ps001/008/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-04-06T13:04:06-05:00"><title>8th | Showcase</title><link rel=manifest href=/visualcomputing/manifest.json><link rel=icon href=/visualcomputing/favicon.png type=image/x-icon><link rel=stylesheet href=/visualcomputing/book.min.4b35fed0bea034bbc19c89c71e14b73fb9c68cfcc586b9382adfb9b7b103ba06.css integrity="sha256-SzX+0L6gNLvBnInHHhS3P7nGjPzFhrk4Kt+5t7EDugY=" crossorigin=anonymous><script defer src=/visualcomputing/flexsearch.min.js></script>
<script defer src=/visualcomputing/en.search.min.cd1ad44dddd2ee065a837df8d7af49418c2f17d0ce74ddff80aecba7f63a83fd.js integrity="sha256-zRrUTd3S7gZag334169JQYwvF9DOdN3/gK7Lp/Y6g/0=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/themes/prism-okaidia.min.css integrity="sha512-5HvW0a7ihK3ro2KhwEksDHXgIezsTeZybZDIn8d8Y015Ny+t7QWSIjnlCTjFzlK7Klb604HLGjsNqU/i5mJLjQ==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/line-numbers/prism-line-numbers.min.css integrity="sha512-3/cdM9qaJ5lBlzRKqwhMw+ZcNCVonz66BO6HgJudG/P1azm9wFrru31SsBa4T4Ew1AOH8HfDXSWS6emWwPl42A==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/prism.min.js integrity="sha512-UOoJElONeUNzQbbKQbjldDf9MwOHqxNz49NNJJ1d90yp+X9edsHyJoAs6O4K19CZGaIdjI5ohK+O2y5lBTW6uQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/line-numbers/prism-line-numbers.min.js integrity="sha512-QTYXYEniHb1m0ZKtSyfpmw40uH9vPfV07vxsv/plIRMEiON4yOp2qoZiv/FTqFIOym4bdQ4+p9RtHaCMC0ApRw==" crossorigin=anonymous referrerpolicy=no-referrer></script><style>.line-numbers-rows>span{display:block;counter-increment:linenumber;line-height:1.5rem}</style></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/visualcomputing/><span>Showcase</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Problem Sets</span><ul><li><input type=checkbox id=section-076859a6cca38d464e24cfb9d51db697 class=toggle checked>
<label for=section-076859a6cca38d464e24cfb9d51db697 class="flex justify-between"><a role=button>Problem set 1</a></label><ul><li><a href=/visualcomputing/docs/Problem-sets/ps001/001/>1st</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/002/>2nd</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/004/>4th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/005/>5th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/008/ class=active>8th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/video/>Video</a></li></ul></li><li><input type=checkbox id=section-07d68b94071726c941f311623e5cdb70 class=toggle>
<label for=section-07d68b94071726c941f311623e5cdb70 class="flex justify-between"><a role=button>Problem set 2</a></label><ul><li><a href=/visualcomputing/docs/Problem-sets/ps002/video/>Video</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/001/>Determinación de superficies</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/image-processing/>Procesamiento de imágenes</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/project/>Proyecto visual</a></li></ul></li></ul></li></ul><ul><li><a href=/visualcomputing/posts/>Integrantes</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/visualcomputing/svg/menu.svg class=book-icon alt=Menu></label>
<strong>8th</strong>
<label for=toc-control><img src=/visualcomputing/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#exercise-08>Exercise 08</a><ul><li><a href=#introduction>Introduction</a></li><li><a href=#previous-work>Previous work</a></li><li><a href=#considerations>Considerations</a></li><li><a href=#solution>Solution</a></li><li><a href=#code>Code</a></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#future-work>Future work</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=exercise-08>Exercise 08
<a class=anchor href=#exercise-08>#</a></h1><blockquote class="book-hint info">Implement a pixelator video application and perform a benchmark of the results (color avg vs spatial coherence). How would you assess the visual quality of the results?</blockquote><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><p>A pixel is any of the small discrete elements that together constitute an image (as on a television or digital screen), the word <em>Pixelated</em> is used to describe digital images in which individual pixels are discernable, as when you look closely at a large photo and can see the tiny dots that make up the image. <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> In this exercise, we mean by pixelator an application capable of taking a media and make it pixelated</p><h2 id=previous-work>Previous work
<a class=anchor href=#previous-work>#</a></h2><p>In the e-book of our class, a Pixelator of images using the library p5.quadrille.js<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> can be found<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. GitHub user <em>mfmyip</em> created an open source code of a video and image Pixelator using Spatial coherence<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></p><h2 id=considerations>Considerations
<a class=anchor href=#considerations>#</a></h2><p>Even though p5.quadrille.js says it works with objects of type p5.Image or p5.Graphics, and a video should work, this is not the case, or at least the implementation proved harder than expected.
The Pixelator made by mfmyip worked without libraries, so it was used as an inspiration for this exercise. mfmyip made unnecessary functionalities such as an option to toggle round pixels and it worked with both images and videos, but just for spatial coherence.
The main idea that makes this work is an array of pixels of the format</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#a6e22e>pixels</span> <span style=color:#f92672>=</span> [<span style=color:#a6e22e>R0</span>, <span style=color:#a6e22e>G0</span>, <span style=color:#a6e22e>B0</span>, <span style=color:#a6e22e>A0</span>, <span style=color:#a6e22e>R1</span>, <span style=color:#a6e22e>G1</span>, <span style=color:#a6e22e>B1</span>, <span style=color:#a6e22e>A1</span>, ...]
</span></span></code></pre></div><p>Where Ri := Red component of pixel i, Gi := Green component of pixel i, Bi := Blue component of pixel i, Ai := Alpha component of pixel i. According to the RGBA color model <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> and moving from left to right across each row, then down each column.</p><p>Assuming an mp4 video doesn&rsquo;t have relevant values for the Alpha component, we will ignore them.</p><p>This 1-dimensional array can be used to implement both algorithms using arithmetic.</p><p>Following the same design philosophy of mfmyip, the P5 canvas contains only the video, and to control it we use keystrokes.</p><p>The following table specifies the available options to control the video</p><table><thead><tr><th>Option</th><th>Key</th></tr></thead><tbody><tr><td>Play/Pause</td><td><em>P</em> or <em>p</em></td></tr><tr><td>Mute/Unmute</td><td><em>M</em> or <em>m</em></td></tr><tr><td>Decrease pixel size</td><td><em>,</em></td></tr><tr><td>Increase pixel size</td><td><em>.</em></td></tr><tr><td>Toggle between original, spatial coherence and color average</td><td><em>T</em> or <em>t</em></td></tr><tr><td>Take snapshot</td><td><em>space</em></td></tr></tbody></table><blockquote class="book-hint warning">Click on the video before executing an option if it doesn&rsquo;t work, to ensure you are in the same context as the video</blockquote><blockquote class="book-hint warning">If there&rsquo;s a bug of a black screen when loading the page, please pause and unpause until the video starts, if there&rsquo;s a bug of Inf frame rate, toggle the video or change pixel size.</blockquote><h2 id=solution>Solution
<a class=anchor href=#solution>#</a></h2><iframe id=ex08 style=width:720px;height:724px srcdoc="
        <!DOCTYPE html>
        <html>
          <head>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js></script>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.sound.min.js></script>
            
            
            
            
            
            <script src=/visualcomputing/sketches/ps001/ex08.js></script>
          </head>
          <body>
          </body>
        </html>
      "></iframe><p>The standard method to benchmark noise is the signal-to-noise ratio (SNR), which measures the &ldquo;noise&rdquo; compared to the real signal. We could take the original source as a base and compare that to the noise generated by the pixels</p><p>A proposal for a benchmark of the pixelated video
<link rel=stylesheet href=/visualcomputing/katex/katex.min.css><script defer src=/visualcomputing/katex/katex.min.js></script>
<script defer src=/visualcomputing/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\(x\)</span>
against the original video <span>\(y\)</span>
could be, for a single frame</p><span>\[BenchmarkFrame(x, y, f) = sum(|Y_y - Y_x|)\]</span><p>or</p><span>\[BenchmarkFrame(x, y, f) = avg(|Y_y - Y_x|)\]</span><p>Where the matrix <span>\(Y_i\)</span>
represents the Luma of video <span>\(i\)</span>
, frame <span>\(f\)</span>
in the color space YCbCr. We do this because the luma represents the perception of the human eye better than the RGB space <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.
Therefore, an objective benchmark is to get the absolute value of the difference between two lumas pixel by pixel, and then reduce this to one dimension by either summing every result or averaging, because every pixel counts but we want something similar to a measure of central tendency.</p><p>To get the benchmark of the whole video, calculate for all frames and get the median. Values closer to <span>\(0\)</span>
are better.</p><p>Another benchmark to be aware of is the performance of the video, doing an average takes more computational work than just selecting a particular pixel, therefore Spatial Coherence should be faster. In this video, the original frame rate is about <strong>60 to 61 fps</strong>, whereas the frame rate using spatial coherence with default pixel size is about <strong>13 fps</strong>, and the frame rate using average with the same characteristic is about <strong>10 to 12 fps</strong>.</p><h2 id=code>Code
<a class=anchor href=#code>#</a></h2><details><summary>Source code</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps001/ex08.js class=line-numbers></pre></div></details><h2 id=conclusions>Conclusions
<a class=anchor href=#conclusions>#</a></h2><p>The performance from the original video to the different methods of pixelation is highly noticeable, between these methods, due to the bigger computational requirements of color averaging, this last one is slower than the spatial coherence in about 1 frame per second.</p><h2 id=future-work>Future work
<a class=anchor href=#future-work>#</a></h2><p>Implement the benchmarking using YCbCr.</p><h2 id=references>References
<a class=anchor href=#references>#</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>“Definition of PIXEL,” Mar. 27, 2023. [Online]. Available: <a href=https://www.merriam-webster.com/dictionary/pixel>https://www.merriam-webster.com/dictionary/pixel</a>. [Accessed: Mar. 29, 2023]&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>nakednous, “p5quadrille.js.” GitHub, Feb. 05, 2023 [Online]. Available: <a href=https://github.com/objetos/p5.quadrille.js/>https://github.com/objetos/p5.quadrille.js/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>“Spatial Coherence | Visual Computing.” [Online]. Available: <a href=https://visualcomputing.github.io/docs/visual_illusions/spatial_coherence/>https://visualcomputing.github.io/docs/visual_illusions/spatial_coherence/</a>. [Accessed: Mar. 29, 2023]&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>mfmyip, “Pixelator.” GitHub, 2020 [Online]. Available: <a href=https://github.com/mfmyip/Pixelator>https://github.com/mfmyip/Pixelator</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>“Portable Network Graphics (PNG) Specification (Second Edition).” [Online]. Available: <a href=https://www.w3.org/TR/2003/REC-PNG-20031110/index.html>https://www.w3.org/TR/2003/REC-PNG-20031110/index.html</a>. [Accessed: Mar. 29, 2023]&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>H. Noda, N. Takao and M. Niimi, &ldquo;Colorization in YCbCr Space and its Application to Improve Quality of JPEG Color Images,&rdquo; 2007 IEEE International Conference on Image Processing, San Antonio, TX, USA, 2007, pp. IV - 385-IV - 388, doi: <a href=https://doi.org/10.1109/ICIP.2007.4380035>10.1109/ICIP.2007.4380035</a>.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/file-highlight/prism-file-highlight.min.js integrity="sha512-FWNmm0IyLo0UvBFHCvBmbxEN5M9hELGsEvI6C+77AloPqCUnwGfi7mTJWun6eov18cs8gB6Svh00iwUVqtNQjQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/judelgadoc/visualcomputing/commit/1721b137cbc71d7f1abab14da609419d8e530762 title='Last modified by judelgadoc | April 6, 2023' target=_blank rel=noopener><img src=/visualcomputing/svg/calendar.svg class=book-icon alt=Calendar>
<span>April 6, 2023</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#exercise-08>Exercise 08</a><ul><li><a href=#introduction>Introduction</a></li><li><a href=#previous-work>Previous work</a></li><li><a href=#considerations>Considerations</a></li><li><a href=#solution>Solution</a></li><li><a href=#code>Code</a></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#future-work>Future work</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></div></aside></main></body></html>