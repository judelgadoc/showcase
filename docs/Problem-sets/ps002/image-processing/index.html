<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Ejercicio # Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:
A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance. A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy. Integrate luma and other coloring brightness tools."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Procesamiento de imágenes"><meta property="og:description" content="Ejercicio # Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:
A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance. A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy. Integrate luma and other coloring brightness tools."><meta property="og:type" content="article"><meta property="og:url" content="https://judelgadoc.github.io/visualcomputing/docs/Problem-sets/ps002/image-processing/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-06-19T16:58:21-05:00"><title>Procesamiento de imágenes | Showcase</title><link rel=manifest href=/visualcomputing/manifest.json><link rel=icon href=/visualcomputing/favicon.png type=image/x-icon><link rel=stylesheet href=/visualcomputing/book.min.4b35fed0bea034bbc19c89c71e14b73fb9c68cfcc586b9382adfb9b7b103ba06.css integrity="sha256-SzX+0L6gNLvBnInHHhS3P7nGjPzFhrk4Kt+5t7EDugY=" crossorigin=anonymous><script defer src=/visualcomputing/flexsearch.min.js></script>
<script defer src=/visualcomputing/en.search.min.cd1ad44dddd2ee065a837df8d7af49418c2f17d0ce74ddff80aecba7f63a83fd.js integrity="sha256-zRrUTd3S7gZag334169JQYwvF9DOdN3/gK7Lp/Y6g/0=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/themes/prism-okaidia.min.css integrity="sha512-5HvW0a7ihK3ro2KhwEksDHXgIezsTeZybZDIn8d8Y015Ny+t7QWSIjnlCTjFzlK7Klb604HLGjsNqU/i5mJLjQ==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/line-numbers/prism-line-numbers.min.css integrity="sha512-3/cdM9qaJ5lBlzRKqwhMw+ZcNCVonz66BO6HgJudG/P1azm9wFrru31SsBa4T4Ew1AOH8HfDXSWS6emWwPl42A==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/prism.min.js integrity="sha512-UOoJElONeUNzQbbKQbjldDf9MwOHqxNz49NNJJ1d90yp+X9edsHyJoAs6O4K19CZGaIdjI5ohK+O2y5lBTW6uQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/line-numbers/prism-line-numbers.min.js integrity="sha512-QTYXYEniHb1m0ZKtSyfpmw40uH9vPfV07vxsv/plIRMEiON4yOp2qoZiv/FTqFIOym4bdQ4+p9RtHaCMC0ApRw==" crossorigin=anonymous referrerpolicy=no-referrer></script><style>.line-numbers-rows>span{display:block;counter-increment:linenumber;line-height:1.5rem}</style></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/visualcomputing/><span>Showcase</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Problem Sets</span><ul><li><input type=checkbox id=section-076859a6cca38d464e24cfb9d51db697 class=toggle>
<label for=section-076859a6cca38d464e24cfb9d51db697 class="flex justify-between"><a role=button>Problem set 1</a></label><ul><li><a href=/visualcomputing/docs/Problem-sets/ps001/001/>1st</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/002/>2nd</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/004/>4th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/005/>5th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/008/>8th</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps001/video/>Video</a></li></ul></li><li><input type=checkbox id=section-07d68b94071726c941f311623e5cdb70 class=toggle checked>
<label for=section-07d68b94071726c941f311623e5cdb70 class="flex justify-between"><a role=button>Problem set 2</a></label><ul><li><a href=/visualcomputing/docs/Problem-sets/ps002/video/>Video</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/001/>Determinación de superficies</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/image-processing/ class=active>Procesamiento de imágenes</a></li><li><a href=/visualcomputing/docs/Problem-sets/ps002/project/>Proyecto visual</a></li></ul></li></ul></li></ul><ul><li><a href=/visualcomputing/posts/>Integrantes</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/visualcomputing/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Procesamiento de imágenes</strong>
<label for=toc-control><img src=/visualcomputing/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#ejercicio>Ejercicio</a><ul><li><a href=#introducción>Introducción</a></li><li><a href=#antecedentes>Antecedentes</a><ul><li><a href=#antecedentes-de-máscaras>Antecedentes de máscaras</a></li><li><a href=#antecedentes-de-lupa>Antecedentes de lupa</a></li></ul></li><li><a href=#consideraciones>Consideraciones</a><ul><li><a href=#máscaras>Máscaras</a></li><li><a href=#lupa>Lupa</a></li><li><a href=#combinación>Combinación</a></li></ul></li><li><a href=#código>Código</a><ul><li><a href=#máscaras-1>Máscaras</a></li><li><a href=#lupa-1>Lupa</a></li></ul></li><li><a href=#conclusiones>Conclusiones</a></li><li><a href=#trabajo-futuro>Trabajo futuro</a></li><li><a href=#referencias>Referencias</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=ejercicio>Ejercicio
<a class=anchor href=#ejercicio>#</a></h1><blockquote class="book-hint info"><p>Implement an image / video processing app supporting different masks, including other kernel sizes different than 3x3, and:</p><ul><li>A region-of-interest base tool to selectively apply a given mask.Hint: circular regions around the mouse pointer are handy and quite simple to implement by means of glsl distance.</li><li>A magnifier tool. Requires a bit of research. For instance, look for it in shadertoy.</li><li>Integrate luma and other coloring brightness tools.</li><li>What other shader tools would you implement?</li></ul></blockquote><h2 id=introducción>Introducción
<a class=anchor href=#introducci%c3%b3n>#</a></h2><p>Inicialmente, planeamos hacer un app que cargue una imagen y realice cuatro acciones con shaders. Tres máscaras y un efecto lupa encima de esas máscaras. No obstante encontramos dificultades, por lo tanto, el resultado final resultó siendo dos apps diferentes. Una con las tres máscaras y otra con la lupa, en este reporte mostraremos el proceso creativo que nos llevó a este resultado.</p><h2 id=antecedentes>Antecedentes
<a class=anchor href=#antecedentes>#</a></h2><p>La hoja de ruta que planteamos inicialmente era</p><ol><li>Hacer una app de máscaras por separado usando shaders</li><li>Hacer una app de lupa por separado usando shaders</li><li>Integrar las dos apps en una sola</li></ol><h3 id=antecedentes-de-máscaras>Antecedentes de máscaras
<a class=anchor href=#antecedentes-de-m%c3%a1scaras>#</a></h3><p>Lo primero que hicimos fue revisar el ejemplo más simple que tuviéramos a la mano, en este caso el app del profesor de procesamiento de imágenes<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. El ejemplo del profe es una máscara de convolución de matrices sencilla, perfecto para nuestro objetivo de investigar antecedentes.</p><details><summary>Fragment shader del profesor</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/profe-mask.frag class="language-js line-numbers"></pre></div></details><p>El profesor publica abiertamente el fragment shader de su app, pero el código no aparece directamente, después de hacer ingeniería inversa y entender el fragment shader, solo faltaba tener una idea del código en P5js.</p><h4 id=recuperando-el-código-fuente>Recuperando el código fuente
<a class=anchor href=#recuperando-el-c%c3%b3digo-fuente>#</a></h4><p>Conocemos dos métodos para recuperar el código del profesor directamente desde su página.</p><ul><li>Investigar las fuentes de la página<ol><li>Abrir las herramientas de desarrollo</li><li>Recargar la página</li><li>Ir a la pestaña de fuentes (Sources)</li><li>Buscar el archivo .js que corresponda al sketch de la app</li></ol></li></ul><video controls autoplay loop muted width=720 height=480>
<source src=/visualcomputing/sketches/ps002/image-processing/method01.webm type=video/mp4></video><ul><li>Investigar el tráfico de red de la página<ol><li>Abrir las herramientas de desarrollo</li><li>Recargar la página</li><li>Ir a la pestaña de red (Network)</li><li>La petición que contenga el archivo .js que corresponda al sketch de la app</li></ol></li></ul><video controls autoplay loop muted width=720 height=480>
<source src=/visualcomputing/sketches/ps002/image-processing/method02.webm type=video/mp4></video><p>Gracias a esos pasos podemos conseguir el código fuente para analizar mejor la app
<details><summary>Código (sketch) del profesor</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/profe-sketch.js class="language-js line-numbers"></pre></div></details></p><p>Nótese como la lógica del cambio entre la máscara y la imagen original se encuentra ubicada en el sketch.</p><h4 id=definiciones-matemáticas-de-los-efectos>Definiciones matemáticas de los efectos
<a class=anchor href=#definiciones-matem%c3%a1ticas-de-los-efectos>#</a></h4><p>Con el marco de trabajo para el código y el fragment shader en su lugar, solo falta incorporar las máscaras en sí.</p><p>Para lograr el efecto de blanco y negro, se puede utilizar un método tradicional ampliamente conocido llamado &ldquo;Line projection&rdquo;, el cual ha sido utilizado en programas reconocidos a nivel mundial como Matlab o GIMP.</p><p>Este método, según un artículo de la Universidad de Lanzhou (兰州大学)<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, permite convertir una imagen a escala de grises al proyectar los valores de los píxeles a lo largo de una línea predeterminada. El resultado es una imagen en blanco y negro que conserva detalles importantes.</p><link rel=stylesheet href=/visualcomputing/katex/katex.min.css><script defer src=/visualcomputing/katex/katex.min.js></script>
<script defer src=/visualcomputing/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>
\[I = \alpha_r R + \alpha_g G + \alpha_b B\]</span><p>También ofrecen otros métodos alternativos de su autoría, pero nosotros usaremos el tradicional con <span>\((\alpha_r, \alpha_g, \alpha_b) = (1/3, 1/3, 1/3) \)</span>
, es decir</p><span>\[grayscale = \frac{R + G + B}{3}\]</span><p>Para el efecto borroso hacemos una convolución de matriz 3x3, donde el nivel de borrosidad depende de los pesos que asignemos al kernel.</p><p>Para el efecto negativo sencillamente le restamos a 1 cada componente de color, es decir</p><span>\[ R_{negative} = 1 - R \\
G_{negative} = 1 - G \\
B_{negative} = 1 - B \]</span><h3 id=antecedentes-de-lupa>Antecedentes de lupa
<a class=anchor href=#antecedentes-de-lupa>#</a></h3><p>Intentamos encontrar efectos de lupa usando shaders, pero ninguno de los códigos que encontramos en nuestra investigación parecía compatible con nuestros navegadores, por lo tanto, decidimos intentar buscar una versión que no utilizara shaders.</p><p>Encontramos un código muy interesante <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, el cual consistía en un amplificador de píxeles.</p><details><summary>Amplificador de pixeles</summary><div class=markdown-inner><iframe src="https://toolness.github.io/p5.js-widget/p5-widget.html?id=6&amp;previewWidth=300&amp;baseSketchURL=https%3A%2F%2Fhappycoding.io%2Ftutorials%2Fp5js%2Fnull&amp;p5version=1.0.0&amp;sketch=%0Alet%20img%3B%0A%0Afunction%20setup()%20%7B%0A%20%20createCanvas(300%2C%20300)%3B%0A%20%20img%20%3D%20loadImage('https%3A%2F%2Fhappycoding.io%2Fimages%2Fstanley-1.jpg')%3B%0A%7D%0A%0Afunction%20draw()%20%7B%0A%20%20image(img%2C%200%2C%200)%3B%0A%0A%20%20%2F%2F%20Get%20the%20color%20at%20the%20mouse%20position%0A%20%20let%20c%20%3D%20img.get(mouseX%2C%20mouseY)%3B%0A%0A%20%20%2F%2F%20Change%20the%20fill%20to%20that%20color%0A%20%20fill(c)%3B%0A%0A%20%20%2F%2F%20Draw%20a%20square%20with%20that%20color%0A%20%20square(mouseX%2C%20mouseY%2C%2050)%3B%0A%7D%0A" style="width:100%;background-color:#fff;border:1px solid #ec245e;box-sizing:border-box;min-height:380px"></iframe></div></details><p>Entendimos que con algunas modificaciones, podría servir como la lupa que necesitábamos. Por ejemplo, cambiar el rectángulo para que muestre el conjunto de píxeles alrededor del mouse, en lugar de un solo pixel.</p><h2 id=consideraciones>Consideraciones
<a class=anchor href=#consideraciones>#</a></h2><h3 id=máscaras>Máscaras
<a class=anchor href=#m%c3%a1scaras>#</a></h3><p>Al momento de implementar decidimos agregar más máscaras, actualmente los efectos visuales que aplicamos usando máscaras son</p><ol><li>Blanco y negro</li><li>Borroso (blur)</li><li>Negativo</li><li>Sepia</li></ol><p>La siguiente tabla muestra un manual de usuario de la app de máscaras, lo que toca hacer es presionar una tecla como lo indica la tabla dependiendo de la máscara que se desee aplicar.</p><table><thead><tr><th>Efecto</th><th>Tecla</th></tr></thead><tbody><tr><td>Blanco y negro</td><td>1</td></tr><tr><td>Borroso</td><td>2</td></tr><tr><td>Borroso brillante</td><td>3</td></tr><tr><td>Borroso oscuro</td><td>4</td></tr><tr><td>Negativo</td><td>5</td></tr><tr><td>Sepia</td><td>6</td></tr><tr><td>Original</td><td>0</td></tr></tbody></table><iframe id=masks style=width:720px;height:724px srcdoc="
        <!DOCTYPE html>
        <html>
          <head>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js></script>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.sound.min.js></script>
            
            
            
            
            
            <script src=/visualcomputing/sketches/ps002/image-processing/masks.js></script>
          </head>
          <body>
          </body>
        </html>
      "></iframe><h3 id=lupa>Lupa
<a class=anchor href=#lupa>#</a></h3><p>La lupa se activa al hacer hover en la imagen.</p><iframe id=glass style=width:720px;height:724px srcdoc="
        <!DOCTYPE html>
        <html>
          <head>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js></script>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.sound.min.js></script>
            
            
            
            
            
            <script src=/visualcomputing/sketches/ps002/image-processing/glass.js></script>
          </head>
          <body>
          </body>
        </html>
      "></iframe><h3 id=combinación>Combinación
<a class=anchor href=#combinaci%c3%b3n>#</a></h3><p>Al hacer hover toda la imagen queda donde debería estar la lupa, los controles de teclado para el cambio de máscara siguen funcionando.</p><iframe id=merge style=width:720px;height:724px srcdoc="
        <!DOCTYPE html>
        <html>
          <head>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.min.js></script>
            <script src=https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.sound.min.js></script>
            
            
            
            
            
            <script src=/visualcomputing/sketches/ps002/image-processing/merge.js></script>
          </head>
          <body>
          </body>
        </html>
      "></iframe><h2 id=código>Código
<a class=anchor href=#c%c3%b3digo>#</a></h2><h3 id=máscaras-1>Máscaras
<a class=anchor href=#m%c3%a1scaras-1>#</a></h3><p>Inicialmente, la textura no se ajustaba correctamente al canvas, posiblemente al usar un canvas tipo WebGL el comportamiento de las funciones cambiaban, por lo tanto, utilizamos el vertex shader para ajustar la geometría de la textura.</p><details><summary>Vertex shader de las máscaras</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/shader.vert class="language-js line-numbers"></pre></div></details><p>Durante la implementación del efecto borroso, se cometió un error al modificar los pesos del kernel. Se observó que si la suma total de los pesos del kernel es mayor a 1.0, la máscara resultante muestra un mayor brillo. De manera similar, si la suma de los pesos es menor a 1.0, la máscara tiende a ser más oscura.</p><p>Para evidenciar esta diferencia, se incluyeron tres máscaras de efecto borroso con características distintas:</p><ol><li><p>Suma de pesos del kernel igual a 1.0: Esta máscara aplica un blur estándar a la imagen, conservando un nivel de brillo equilibrado.</p></li><li><p>Suma de pesos del kernel mayor a 1.0: Esta máscara produce un efecto de blur más brillante, ya que los píxeles adquieren valores superiores al aplicarse la máscara.</p></li><li><p>Suma de pesos del kernel menor a 1.0: Esta máscara genera un blur más oscuro, dado que los píxeles se ven afectados por valores inferiores al aplicarse la máscara.</p></li></ol><p>Al experimentar con estas diferentes máscaras de blur, se puede apreciar cómo varían los efectos visuales en función de la suma total de los pesos del kernel utilizado.</p><details><summary>Fragment shader de las máscaras</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/shader.frag class="language-js line-numbers"></pre></div></details><p>Al contrario de lo que aprendimos con el código del profesor, nosotros optamos por implementar la lógica del cambio de máscara directamente en el fragment shader por medio de un condicional sencillo.</p><p>La razón de ser de esta decisión es simplificar en gran medida el código del sketch, puesto que solo tiene que leer un shader y darle valores a sus variables uniformes, que son</p><ol><li><code>uResolutionX</code> y <code>uResolutionY</code>: Tamaño del canvas</li><li><code>maskType</code>: Tipo de máscara (para el condicional)</li><li><code>uTexture</code>: Imágen</li></ol><p>La ventaja de esta aproximación es que es bastante modular, lo que nos permite agregar más máscaras indiscriminadamente, y los únicos cambios que toca realizar son agregar una ramificación en el condicional del shader y otra en el condicional que se encuentra en la función <code>switchMask</code> del sketch.</p><p>De hecho, el efecto de sepia que se incorporó previo a este informe fue generado con la ayuda de ChatGPT. Se le proporcionó intencionalmente un contexto limitado para demostrar la facilidad con la que se pueden agregar nuevos efectos<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><p>Al limitar el contexto proporcionado al modelo de ChatGPT, se buscó mostrar cómo incluso con información limitada, es posible obtener resultados satisfactorios al agregar efectos visuales como el sepia. Esta demostración destaca la capacidad del modelo para comprender y aplicar instrucciones específicas, brindando flexibilidad en la implementación de nuevos efectos sin requerir un conocimiento detallado del proceso subyacente.</p><details><summary>Código (sketch) de las máscaras</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/masks.js class="language-js line-numbers"></pre></div></details><h3 id=lupa-1>Lupa
<a class=anchor href=#lupa-1>#</a></h3><details><summary>Código (sketch) de la lupa</summary><div class=markdown-inner><pre data-src=/visualcomputing/sketches/ps002/image-processing/glass.js class="language-js line-numbers"></pre></div></details><h2 id=conclusiones>Conclusiones
<a class=anchor href=#conclusiones>#</a></h2><p>Combinar una lupa que no utiliza shaders no es fácil, puesto que el shader de la app de máscaras se aplica a la geometría, por eso toda la imagen se aplica en la parte de la lupa, en la parte de la combinación.</p><h2 id=trabajo-futuro>Trabajo futuro
<a class=anchor href=#trabajo-futuro>#</a></h2><p>Hay varias oportunidades de modificación que no abarcamos en este trabajo</p><ol><li>Tal vez P5js tenga alguna como textMode(NORMAL) que permita modificar la geometría, simplificando un poco el código del vertex shader.</li><li>Implementar exitosamente la app de lupa con shaders podría simplificar la combinación de las dos apps, tal vez sea posible implementar directamente lo que tenemos con un poco más de esfuerzo</li><li>Podemos aprovechar la modularidad de nuestro shader para agregar más efectos como Vignette, X-ray entre otros</li><li>El método de Line projection nos permite tomar distintos pesos en los <span>\(\alpha\)</span>
, por ejemplo, inspirados en un workshop de la Universidad de Stanford<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>, creemos que se puede lograr un tinte azul si aumentamos el peso de <span>\(\alpha_b\)</span>
1.2 veces</li><li>Actualmente las máscaras de blur tienen sus parámetros fijos en la definición del shader, pero en un futuro se podría hacer de tal forma que se pueda cambiar los pesos del kernel dinámicamente, ojalá sin disminuir demasiado la naturaleza modular de nuestro trabajo.</li></ol><h2 id=referencias>Referencias
<a class=anchor href=#referencias>#</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Image Processing | Visual Computing. <a href=https://visualcomputing.github.io/docs/shaders/image_processing/>https://visualcomputing.github.io/docs/shaders/image_processing/</a>. Accessed 10 June 2023.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Wan, Yi, and Qisong Xie. “A Novel Framework for Optimal RGB to Grayscale Image Conversion.” 2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), IEEE, 2016, pp. 345–48. DOI.org (Crossref), <a href=https://doi.org/10.1109/IHMSC.2016.201>https://doi.org/10.1109/IHMSC.2016.201</a>.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>“Images in P5.Js.” Happy Coding, 16 Nov. 2020, <a href=https://happycoding.io/tutorials/p5js/images#getting-pixels>https://happycoding.io/tutorials/p5js/images#getting-pixels</a>.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>“Add Sepia Mask.” ChatGPT, <a href=https://chat.openai.com/share/75e3125f-baf7-4381-b49f-263fc86c00e3>https://chat.openai.com/share/75e3125f-baf7-4381-b49f-263fc86c00e3</a>. Accessed 19 June 2023.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>CS101 Introduction to Computing Principles. <a href=https://web.stanford.edu/class/cs101/image-6-grayscale-adva.html>https://web.stanford.edu/class/cs101/image-6-grayscale-adva.html</a>. Accessed 19 June 2023.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/plugins/file-highlight/prism-file-highlight.min.js integrity="sha512-FWNmm0IyLo0UvBFHCvBmbxEN5M9hELGsEvI6C+77AloPqCUnwGfi7mTJWun6eov18cs8gB6Svh00iwUVqtNQjQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/judelgadoc/visualcomputing/commit/c94d28a0c6c2d828ac968660610e9929c0657496 title='Last modified by judelgadoc | June 19, 2023' target=_blank rel=noopener><img src=/visualcomputing/svg/calendar.svg class=book-icon alt=Calendar>
<span>June 19, 2023</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#ejercicio>Ejercicio</a><ul><li><a href=#introducción>Introducción</a></li><li><a href=#antecedentes>Antecedentes</a><ul><li><a href=#antecedentes-de-máscaras>Antecedentes de máscaras</a></li><li><a href=#antecedentes-de-lupa>Antecedentes de lupa</a></li></ul></li><li><a href=#consideraciones>Consideraciones</a><ul><li><a href=#máscaras>Máscaras</a></li><li><a href=#lupa>Lupa</a></li><li><a href=#combinación>Combinación</a></li></ul></li><li><a href=#código>Código</a><ul><li><a href=#máscaras-1>Máscaras</a></li><li><a href=#lupa-1>Lupa</a></li></ul></li><li><a href=#conclusiones>Conclusiones</a></li><li><a href=#trabajo-futuro>Trabajo futuro</a></li><li><a href=#referencias>Referencias</a></li></ul></li></ul></nav></div></aside></main></body></html>